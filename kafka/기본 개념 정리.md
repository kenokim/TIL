## message delivery semantics
- https://docs.confluent.io/kafka/design/delivery-semantics.html
- at least once, exactly-once 와 같은 개념이다.
- producer <-> broker, broker <-> consumer 의 두 구간에 대해 고민해야 한다.

### at least once
- producer, broker, consumer 설정을 각각 조정해서 at least once 를 쓸 수 있다.

### exactly once
- kafka 의 transaction API 를 통해 exactly once 를 사용할 수 있다.
- 단점으로는 성능, 복잡성, 트랜잭션 점유 등이 있다.

## 참고자료
- https://oliveyoung.tech/2024-10-16/oliveyoung-scm-oms-kafka/

---

## broker
### min.insync.replicas, replication factor
#### 1. `replication.factor` (복제 계수)
- **정의**: 각 파티션에 대해 유지할 **복제본(replica)**의 수.
- **역할**: 데이터의 **내구성(durability)**과 **가용성(availability)** 보장.
- **예**:
  - `replication.factor=3` → 3개의 복제본 유지.

#### 2. `min.insync.replicas` (최소 동기화 복제본)
- **정의**: 데이터 쓰기 성공을 위해 **동기화된(in-sync)** 복제본의 최소 수.
- **역할**: 데이터 손실 방지와 쓰기 안정성 보장.
- **예**:
  - `min.insync.replicas=2` → 최소 2개의 복제본이 동기화 상태여야 쓰기 성공.

#### 3. 관계
- `min.insync.replicas`는 항상 `replication.factor`보다 작거나 같아야 함.
- 쓰기 성공 조건:
  - **`acks=all`** 설정 시, 리더와 최소 `min.insync.replicas`가 데이터 동기화 완료.

### cf. AWS, Azure managed kafka
- AWS mks: replication factor, min.insync.replicas 는 사용자가 설정 가능하다.
- Azure event hubs: replication factor = 3 이고, 두 값 모두 사용자가 설정 불가능하다.

---

## producer
### idempotence
- producer 는 message header 에 producerId, sequence 값을 담아서 보낸다.
- broker 는 저장된 message 의 sequence 보다 새로운 message 의 값이 1 더 큰 경우에만 message log 에 저장하며, 이외에는 ACK 만 보낸다.
- 기본 설정은 중복이 가능하고, idempotence 를 켜야 중복이 방지된다.

---

## consumer
### 주요 설정 값
- group.id: consumer group 을 지정한다.
- auto.offset.reset: earliest, latest -> offset 이 없는 경우 파티션의 처음부터/마지막부터 메시지를 읽을지
- enable.auto.commit: offset 자동 커밋 또는 코드로 커밋
- auto.commit.interval.ms: offset 자동 커밋할 경우 interval

### 주요 기능
- subscribe: 메시지를 가져올 topic 을 구독한다. broker 에서 topic 의 metadata 를 가져온다.
- poll: 주기적으로 메시지를 가져온다.
- commit: 다음에 읽을 offset 을 broker 에 기록한다.

### poll 작동 방식

1. parititon 할당: consumer 는 broker에서 partition 할당을 확인한다. 없을 경우 할당을 요청하거나 rebalancing 을 기다린다.
2. heartbeat 전송: consumer 는 broker 에게 heartbeat 를 전송한다. heartbeat 는 session.timeout.ms 내에 전송되어야 한다.
3. fetch 요청: consumer 는 timeout 동안 broker 에게 fetch 를 요청한다. broker 는 offset 부터 지정된 개수의 메시지를 반환한다.
4. 메시지 처리: consumer 는 받아온 메시지를 ConsumerRecords 로 변환한다.
5. offset commit: consumer 는 commit 을 통해 broker 에 offset 을 저장한다.

### consumer rebalacing 이 일어나는 경우
- topic 에 새로운 partition 이 추가되는 경우
- session.timeout.ms 내에 heartbeat 응답이 없는 경우
- max.poll.interval.ms 내에 poll() 을 호출하지 않은 경우
- consumer group 에 새로운 consumer 가 추가되거나 기존 consumer 가 종료되는 경우

### rebalancing mode
- eager mode: 리밸런싱이 발생할 경우 모든 consumer 에게 partition 을 재할당한다. (default)
- cooperative mode: consumer 와 cooperative 한 consumer 만 rebalance 를 한다.
- Kafka는 **Rebalance**를 수행하기 위해 **Partition Assignor**를 사용하며, 각 Assignor는 특정 **Rebalancing Mode**를 따른다.

| **Partition Assignor**         | **Rebalancing Mode**        | **설명**                                                                      |
|---------------------------------|-----------------------------|-------------------------------------------------------------------------------|
| `RangeAssignor`                 | Eager                       | 토픽별로 연속된 파티션을 Consumer에 할당.                                      |
| `RoundRobinAssignor`            | Eager                       | 모든 파티션을 라운드로빈 방식으로 분배.                                        |
| `StickyAssignor`                | Eager                       | 이전 할당을 최대한 유지하며 파티션을 재분배.                                    |
| `CooperativeStickyAssignor`     | Incremental Cooperative     | 기존 할당을 유지하며 필요한 파티션만 추가 또는 제거.                           |
---

## message
- key: 저장될 partition 을 결정한다.
- value: Avro, Json, XML 등이 있다.
  - Avro 는 가볍고 성능이 좋다. Json 은 무겁지만 개발하기가 쉽다.
- headers: 추가 메타데이터, 메시지 타입, 생성 시간, 추적 ID 등
- offset: partition 내의 고유 식별자로 순서를 나타낸다.
- timestamp: 메시지가 생성되거나 등록된 시간을 나타낸다.

### custom serializer/deserializer
- custom serializer/deserializer 를 구현할 경우 producer 와 consumer 가 같은 것을 사용해야 한다.
- 따라서, 이는 권장되지 않으며 Avro, JSON, protobuf 와 같은 표준적인 serializer/deserializer 를 사용하는 것이 좋다.
  - 예를 들어, KafkaAvroSerializer 와 같은 라이브러리를 사용한다.

### `poll()` 호출 시 수행되는 작업
1. **Heartbeat 전송**  
   - Consumer Group의 활성 상태 유지.
   - `session.timeout.ms` 내에 Heartbeat가 없으면 Rebalancing 발생.

2. **Partition 할당 확인**  
   - Rebalancing 이후 할당된 파티션 확인.
   - 할당된 파티션이 없으면 데이터 반환 없음.

3. **Fetch Request**  
   - 할당된 파티션의 메시지를 브로커로부터 요청.
   - 배치 단위로 데이터 가져옴 (`fetch.min.bytes`, `fetch.max.bytes` 설정).

4. **메시지 역직렬화**  
   - `key.deserializer`와 `value.deserializer`를 사용해 메시지를 읽기 가능한 형태로 변환.

5. **오프셋 관리**  
   - 메시지 처리 후 오프셋 기록.
     - **자동 커밋**: `enable.auto.commit=true`.
     - **수동 커밋**: `enable.auto.commit=false`.

6. **Rebalancing 처리**  
   - Consumer Group 내 변경이 발생하면 Rebalancing 수행.
   - 파티션 재할당 발생 시, Listener 호출(`onPartitionsRevoked`, `onPartitionsAssigned`).

7. **ConsumerRecords 반환**  
   - 처리할 메시지(`ConsumerRecords` 객체)를 애플리케이션으로 반환.

---

---

## SASL 인증
- tls 와 sasl 을 함께 사용할 수 있다.
- sasl 메커니즘 옵션에 따라 작동 방식이 다르다.

### 예시: Kafka SASL/PLAIN 인증 검증 과정

#### 1. 클라이언트 인증 요청
- 클라이언트는 Kafka 브로커에 연결 후 `\0username\0password` 형식으로 인증 요청.

#### 2. 브로커에서 JAAS 설정 확인
- 브로커는 `server.properties` 파일의 JAAS 설정으로 자격 증명을 검증:
  ```properties
  listener.name.sasl_plaintext.plain.sasl.jaas.config= \
    org.apache.kafka.common.security.plain.PlainLoginModule required \
    username="kafka_user" \
    password="kafka_password";

## 재시도 및 실패 처리
### DLQ 패턴
